[["index.html", "Conclusion Chapter 1 Introduction", " Conclusion Sara Souther 2024-09-26 Chapter 1 Introduction This course surveys the central concepts in ecology: evolution, population dynamics, community interactions, biogeochemical cycling, and limiting factors, as well as how those factors are measured, quantified, and interact with drivers of global environmental change. This course is required for the B.S. in Environmental Sciences degree program, and also the B.S. in Environmental and Sustainability Studies degree. This course acquaints students with foundational concepts and theories in ecology and provides a broad basis for more advanced courses in subdisciplines and applications of ecology. A critical part of ecological research is developing practical and analytic skills. Most ecologists and data scientists use R statistical software. Learning how to manage, manipulate and analyze data in R will serve your undergraduate career and beyond! In ENV 226 lab, we will ease you into using R for all your data needs! How to use this resource Each chapter in this online book corresponds to a lesson that will help you in lab. When starting a new chapter, create a new R script with a name that allows you to easily connect the content in the R script to the chapter. Then, copy and paste sections of code in the chapter into your R script to practice! "],["welcome-to-r.html", "Chapter 2 Welcome to R! 2.1 R and R studio installation 2.2 Download the R statistical software from the official R Project website. 2.3 Download R studio 2.4 Set up R studio 2.5 Working directories 2.6 Annotating your code 2.7 Organizing your code", " Chapter 2 Welcome to R! R is an open source statistical software package commonly used by researchers and other folks, who crave a free way to manipulate, analyze, and visualize date. R uses it’s own programming language, which is similar to S+ (the paid precursor to R). R employs an object-oriented programming (OOP) paradigm, specifically a type of OOP known as “class-based object-oriented programming,” to manage and manipulate data. In R, objects are fundamental entities, and you work with data and functions through objects. Let’s walk through the basics of installing and using R! 2.1 R and R studio installation You will first want to download R statistical software and R studio, which is a powerful program that interfaces with R to make your coding experience more organized and enjoyable. Notice that you need to select a version of R depending on your operating system. 2.2 Download the R statistical software from the official R Project website. Open your web browser and go to the official R Project website at https://www.r-project.org/. Choose a CRAN Mirror: On the R Project website’s main page, you’ll see a section that says “Download and Install R.” Click on the link that says “CRAN (Comprehensive R Archive Network).” This will take you to the CRAN website. Select Your Mirror: On the CRAN website, you’ll find a list of mirrors (servers) from which you can download R. Choose a mirror that is geographically close to your location, as this will generally provide faster download speeds. Click on the mirror’s link. Download R for Your Operating System: On the mirror’s page, you’ll see options to download R for various operating systems (e.g., Windows, macOS, Linux). Click on the appropriate link for your operating system. Choose the Latest Version: You’ll typically see multiple versions of R available for download. It’s recommended to choose the latest stable version unless you have a specific reason to use an older version. Download and Install: After clicking on the download link, the installation file for R will begin downloading. Once the download is complete, run the installer and follow the installation instructions for your operating system. Start Using R: After the installation is complete, you can launch R from your computer. First, let’s install RStudio, a popular integrated development environment (IDE) for R, to enhance your R programming experience. 2.3 Download R studio Now download R studio! Visit the RStudio Website: Open your web browser and go to the official RStudio website at https://www.rstudio.com/. Download RStudio: On the RStudio website’s main page, click on the “Products” menu at the top, and then select “RStudio” from the dropdown menu. Choose the RStudio Edition: RStudio offers different editions, including RStudio Desktop (for use on your local machine), RStudio Server (for remote access), and RStudio Workbench (formerly known as RStudio Server Pro, designed for collaboration and sharing in enterprise environments). You will want to choose the free version, RStudio Desktop. Download the Installer: After selecting the edition, you’ll be directed to a page with download options. Click on the download link for your operating system (e.g., Windows, macOS, Linux). Download and Install: The installation file for RStudio will begin downloading. Once the download is complete, run the installer and follow the installation instructions for your operating system. Start Using RStudio: After the installation is complete, you can launch RStudio from your computer. 2.4 Set up R studio Alright, now that you’ve downloaded R and R studio, open R studio. You can customize the panes that you are visualizing in R. In RStudio, the four panels or panes are commonly referred to as: Source Pane: This is where you can write, edit, and save your R scripts and code files. It is typically used for script development and editing. You can open and create new R script files in this pane. Console Pane: The console is where you interact with R directly. You can execute R commands and see their output here. It’s an interactive environment where you can test and run R code line by line or in batches. Environment Pane: The environment pane displays information about the objects, data frames, variables, and functions currently loaded in your R session. You can also use this pane to view data frames in a spreadsheet-like format and manage your workspace. Files/Plots/Packages/Help Pane: This pane has multiple tabs and serves various purposes: Files: It shows the file system of your project, allowing you to navigate and manage files and directories. Plots: When you create plots in R, they will appear in this tab. You can interact with and export the plots from here. Packages: This tab displays information about installed packages, and you can use it to install, update, or load packages. Help: When you need documentation or help for R functions or packages, you can use the Help tab to search for and view documentation. Typically, I select a structure in which I have my Source pane in the upper left, my Console Pane in the lower left position, my Environment Pane in the upper right corner, and the Files/Plots/Packages/Help Pane in the lower right position. You can select any position that you’d like, but if we create the same work environment, it will be easy for me to direct you when we are trouble-shooting code. To adjust the panels positions, use the pane layout function. Here’s what that looks at for a Mac, but typically this arrangement is the default positioning for panels in R studio, so you likely won’t have to adjust positioning! 2.5 Working directories When you are coding in R, you will want to save your R or R markdown scripts and any other data files (e.g., .csv or spatial files) that you are analyzing in a common file. With good housekeeping, you will be able to seamlessly rerun your analyses at in point in time, allowing you to pick back up on projects that may have been dormant! The first step in good R housekeeping is to set a working directory. A working directory tells R where to look for and save files. As an example, let’s say I am planning to save everything associated with this tutorial to a file called Class1_IntroToR. To do this, create a new folder on your desktop called ‘R is great’. You can change your working directory using the R studio interface by selecting a working directory at the top of the console panel in the “Files” tab. If you want to change your working directory to a different location, click on the “…” (ellipsis) button in RStudio’s “Files” tab. This will allow you to browse your file system and select a new directory as your working directory. That said, you will be far better served by including code in your R script that directs R to your working directory. I prefer to set it within the code in order to allow you to instantaneously be able to pick up work where you left off rather than searching through files and trying to remember how you set up the code. You can view your working directory by running a simple bit of code (run code below). getwd() #display file path to R studio ## [1] &quot;/Users/sks379/Desktop/ENV226LabRManual&quot; When you run, getwd() you will see where R is looking for files. Now, let’s tell R where we want it to access files from! First, you will need to identify your file path. To find the file path to the Class1_IntroToR on a mac, double click on the file and should see several option, including ‘Get info’ (check out picture below). Then, select ‘Get info’. Then, highlight the information after ‘where’ and copy it as a pathname (see picture). For PCs, start by opening your File Explorer: Press the Windows key + E on your keyboard. Alternatively, you can click the “File Explorer” or “This PC” icon on your taskbar or Start menu. Navigate to the Folder: Use the File Explorer to navigate to the folder where the file is located. You can click on folders to open them and view their contents. Find the File: Locate the file you are interested in within the folder. View the File Path: Once you’ve found the file, you can see its full file path in the address bar at the top of the File Explorer window. The file path will be displayed as a sequence of folder and file names separated by backslashes. You can click in the address bar and copy the file path to the clipboard by pressing Ctrl + C after selecting it. Once you have copied your file path, paste that path name into the following code and set your working directory: setwd(“/Users/sks379/Desktop/R is great/”) Now R studio is directed to upload and save work to this folder. 2.6 Annotating your code Notice anything about the code in the section you just ran? You can use the hast tag symbol to tell R not to run a section of code. Whenever I am generating code, I try to add lots of notes to myself, so that that future me knows what code I created and why. Annotating your code is just good practice for coding! Alternatively, you can create R markdown files (what this tutorial has been created in), but R markdown, while generating pretty PDFs and websites, adds an extra layer of complexity that you generally don’t want or need while coding, so I typically recommend creating an R script and annotating your that file! One thing that you might want to include in your code description is the version of R that you are using (you may need to load older versions of R if your scripts stop working due to updates to the program). To check the version of R that you are using, paste this in the command line: R.version.string ## Libraries Base R, the fundamental, built-in set of functions, data structures, and libraries that come with the R programming language without the need for additional packages or extensions, including basic math functions, statistical analyses and visualization tools. However, one amazingly cool think about R is that folks are out there creating ‘libraries’, or a collection of R functions, data sets, and documentation bundled together into a single package, to do specialized analyses. For most tasks in R, you will need to install and load libraries. There are two methods to install libraries. Let’s start by installing an important library (or package) for data manipulation, called ‘tidyverse’ (actually several packages - hence why the name references a universe). To do this, run this code: install.packages(“tidyverse”). The weird thing about including install packages code is that you don’t want to re-install packages every time that you use R (in fact, it caused my R markdown code to freak out, which is why I’ve included the install function in the text). You will need to load packages, you generally won’t need to install packages after you have done it once. You can either then install the packages and delete the install code OR you can install through the R studio interface by going to packages, selecting install and searching for and installing the packages that you are interested in. When prompted, be sure to install dependencies - this will make sure that you have any pieces of code that the library that you are installing needs to operate. Excellent! You have installed a library! Now, we need to load it. You WILL need to load R packages every time that you use R. Any functions associated with your package won’t work, unless the package is loaded, so I suggest keeping the load library code in your R script. The code to load libraries is simple (see below). library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.4 ✔ readr 2.1.5 ## ✔ forcats 1.0.0 ✔ stringr 1.5.1 ## ✔ ggplot2 3.5.1 ✔ tibble 3.2.1 ## ✔ lubridate 1.9.3 ✔ tidyr 1.3.1 ## ✔ purrr 1.0.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors 2.7 Organizing your code A well-written R script will include the components we have been discussion: Annotated notes on what the script is doing and potentially even the version of R, loading commands for your libraries, and a line of code specifying your working directory. With these elements in place, you are ready to code your heart out! Here is a glimpse at what your R scripts should look like. ## Importing and exporting .csv files You may want to import data, and export a .csv file after analyses to include as a table in your results. The code to do this is simple: Finally, one easy way to export plots is to use the ‘Plots’ tab in your R studio window. Simply click on the ‘Plots’ tab and select export - you can choose different file types and sizes when you export. Here is a nice example of a R script: Download the R file And with that, welcome to the wonderful world of coding in R! "],["descriptive-statistics.html", "Chapter 3 Descriptive statistics 3.1 What can statistics tell us? 3.2 Sampling populations 3.3 Data types 3.4 Describing data 3.5 Figures 3.6 Summary 3.7 Assignment", " Chapter 3 Descriptive statistics 3.1 What can statistics tell us? Welcome to our statistical exploration of the natural world! Almost all statistical analysis boils down to answering 1 of 2 questions: Do these groups differ? Is there a relationship between these variables? These seem like relatively simple questions to answer, perhaps just by looking at our data, so Why do we need statistics? The short answer is: error and sampling! Whenever we collect data, we introduce error; our instruments are imprecise and do not capture an exact measure of whatever you are measuring (e.g., height, weight), and humans make mistakes during measurement collection. Secondly, we are always measuring a sub-sample of the true population (true population meaning all representatives of whatever you are trying to measure; this can be grass, marbles, or the tibia of humans). Not only is in intractable in most cases to measure all individuals of whatever you are interested in, even when it is possible to attempt to measure all individuals (like in the case of rare plant work), statistics acknowledges that it is still unlikely that we are able to completely measure all individuals in your focal population, since individuals may be dormant or challenging to locate. If we could measure all individuals of our population of interest with perfect accurately, we could calculate population parameters, or quantities describing populations like averages and variation, rather than estimating these metrics, and just compare them. In this way, statistics is inherently practical, and asks: What can we say about whatever we are looking at, given our numerous flaws? 3.2 Sampling populations After a few classes, we will explore sampling methodology in greater depth in order to design appropriate experiments that test a statistical hypothesis. Let’s quickly talk about sampling now so that we have a shared understanding and vocabulary to build on - after all, statistics really centers around estimating characteristics of a true population from a sample. The really, truly amazing thing is that by properly applying statistics, we can learn practically anything about almost any population using samples! In statistics, a population refers to the all units of the thing that you are interested (i.e., all suriname frogs, all grains of sand, all aspen leaves from a genotype found in southern Arizona). Note: Population in statistics differs from the term population in population ecology, where a population refers to a group of individuals in a particular area that interbreed. A sample is a subset of the population that we measure to infer something about the population. Statistical analyses depend on a random sample or must account for non-randomness within the sample. Just imagine, for instance, that you were interested in whether coat color in cats differed between house cats and feral cats. To select the house cat sample, you randomly select house numbers, visit the house and record coat color, thus collecting a random sample. However, to survey feral cats, you go to several cat colonies at night and record the first cat that you see, which are always white or tan. The sample of feral cats introduces bias, and causes you to overestimate the number of light colored feral cats, and underestimate dark feral cats. We can conduct statistical analysis until the cats come home (ha!), but if your sample is biased, our results will always be meaningless. In the cat example, it was pretty obvious that the researcher was introducing bias, BUT it is REALLY easy to introduce bias in ecological and social research on accident! Imagine that you looking at fire effects on vegetative communities in the Sonoran. In high severity burn areas, there are thickets of cat’s claw (a pokey plant). Without proper field sampling protocols, it is very tempting to avoid establishing plots in the cat claw thickets, thus not capturing true differences in vegetation along burn severity gradients. We can go over field sampling methodology later, but let’s talk about several types of appropriate sampling strategies. The key is that we want our sample to be representative of the true population, so that estimates of values (i.e., means, variance) from the sample represent true population parameters. Simple Random Sampling is when every sample has an equal likelihood of being selected. We can quickly and easily generate such a sample in R, using the sample function. sample(1:100, 10, replace=FALSE) ## [1] 47 28 21 68 33 5 8 32 7 70 #1:10000 = numbers to chose among #number of random numbers you wish to generate #to replace or not (in other words do you wish for the same number to be selected multiple times) Random Cluster Sampling randomly select groups (aka clusters) within a population. This sampling design is used commonly in ecology, when we select random locations for plots, then measure all individuals within those plots. If for instance, we are interested in Ponderosa Pine growth rates on the Coconino National Forest, we would randomly assign points across Pondo habitat on the Coconino. At each point, we would set up a plot in which we measure Ponderosa Pines within an 11.71m radius plot. Why wouldn’t we just go out to a point and measure 1 tree to create a totally random sample? The plots are randomly assigned (yay!), but the trees within the plots are not independent. In other words, we might expect measures of trees within plot A to be more similar to each other than they are to trees within plot B, due to differences in microsite characteristics, genetic similarity among co-occurring trees, or site history (logging, fire). Luckily, we can account for this non-independence, as long as the plots are random! Stratified Sampling draws samples using proportionality based on homogeneous groupings known as strata. This type of sampling is frequently used in ecology to account for landscape differences in key factors. For instance, say you asked to classify vegetation types for a Nature preserve in southern Arizona. The reserve has a large riparian area (25% of the property) with completely different vegetation from the upland area (75%). Random sampling might, by chance, under or over represent one of these two areas. To create a stratified sampling design, you would ensure proportional representation of both areas by randomly placing 25% of the sample points within the riparian area, and 75% of the sample points within the upland area. Sample size More is better. However, practically we are often limited by time and money! Statistical analysis is only one part of presenting your research results. Generally, a results section in a manuscript includes: statistical results, data description (e.g., describing means, ranges, maxima, minima of groups of interest), and data visualization (i.e., creating beautiful figures). For each analysis that we cover, we will talk about how to present statistical results, describe data, and create appropriate supporting figures. 3.3 Data types Before we start learning to present research results (analysis, description, visualization), let’s talk about data! Data comes in several varieties, and the variety dictates which statistical analysis we choose! Categorical variables are non-numeric variables. Examples: Pet type (dog, cat, fish, bird), Size (small, medium, large), Car type (sedan, SUV), Present/Absent Numerical variables are variables that are numbers, and occur in two forms: *Discrete = Counts of things (no decimal points/fractions) Data are discrete when it does not make sense to have a partial number of the variable. For instance, if counting the number of insects in a pond, it does not make sense to count a half a species. Examples: Number of people in a building, number of trees in a plot, number of bugs in a pond Continuous are numerical data that can occur at any value. These are variables that can occur in any quantity. If you can have a fraction of this variable, it is continuous. Examples = Height, Weight, Length Ordinal variables (sometimes referred to as ranked) can be categorical or numerical, but the order matters. Examples = Grades (A, B, C, D, E), Likert scale variables (Strongly disagree, Agree, Strongly Agree), Class rank (1, 2, 3, 4, 5) 3.4 Describing data First, let’s take a spin with data description. We are starting here to introduce a few concepts that will be important to understand, as we launch into statistical analysis. We will start by describing continuous data. Let’s use a simplified version of a dataset that I’m working with right now to look at the performance of several species of pollinator-friendly native species in agricultural gardens. Eventually, we’d like to develop seed to provide to restorationists for restoration of arid and semiarid grasslands. To do this, we need to understand how reliable these species are at establishing, producing seed, and attracting pollinators. Initially, we are conducting experiments with multiple populations of each species to determine how consistently plants grow, reproduce, and perform. Here, We will take a look at the initial heights of 1 population of one species, Asclepias subverticulata. Most of the time when writing up results, you present a mean (sum of numbers divided by the number of observations), and an estimate of variation (a measure of how different the observations are). Here, we calculated three estimates variation, variance, standard deviation, and standard error. #create vector of heights (cm) of one population of A. subverticulata sedonapopulation &lt;- c(3, 3, 3, 3, 7, 8, 9) #take the mean mean(sedonapopulation) ## [1] 5.142857 #calculate variance var(sedonapopulation) ## [1] 7.47619 #calculate standard deviation sd(sedonapopulation) ## [1] 2.734262 #calculate standard error #base r doesn&#39;t have this function #so we have to write our own std_error &lt;- function(x) sd(x)/sqrt(length(x)) std_error(sedonapopulation) ## [1] 1.033454 Since you will occasionally need to include equations in your write-ups, let’s get use to mathematical syntax, with these simple examples. The formula for the sample mean is: \\(\\mu = \\frac{\\Sigma x_i}{n}\\); where \\(\\mu\\) indicates the sample mean (sample = group of numbers we are looking at); \\(\\Sigma\\) means to add what ever follows; \\(x_{i}\\) is the value of one observation; (subscript i is often used to indicate that the action should be repeated for all values); \\(n\\) is the number of observations Why didn’t we just use \\(\\bar{x}\\) to indicate the mean? Because statisticians typically use \\(\\bar{x}\\) to indicate the true mean of the population, and \\(\\mu\\) to indicate the sample mean! Just to show you, what the mean() function is doing, let’s run: sum = 3+3+3+3+7+8+9 #add all the numbers in the sample n = length(sedonapopulation) #or you can just calculate the number of height measurements mean = sum/n; mean #divide sum by number ## [1] 5.142857 This formula is simple, but sometimes with more complex formulas, I will solve the equations by hand, to make sure that I understand what is happening! The formula for variance is: \\(S^{2} = \\frac{\\Sigma(x_i - \\mu)^{2}}{n - 1}\\) where \\(S^{2}\\) is the sample variance; \\(\\mu\\) is the sample mean (remember from above); \\(x_{i}\\) is the value of one observation; \\(n\\) is the number of observations In other words: #We determine how much each observation varies from the mean. diffobs1 = mean - 3 diffobs2 = mean - 3 diffobs3 = mean - 3 diffobs4 = mean - 3 diffobs5 = mean - 7 diffobs6 = mean - 8 diffobs7 = mean - 9 #Then we square each of these. diffobj1_sq = diffobs1^2 diffobj2_sq = diffobs2^2 diffobj3_sq = diffobs3^2 diffobj4_sq = diffobs4^2 diffobj5_sq = diffobs5^2 diffobj6_sq = diffobs6^2 diffobj7_sq = diffobs7^2 Why do we square the differences rather than just adding them up? Because differences will be positive and negative. If we added them without squaring, sample differences would negate each other. We want an estimate of the absolute differences of samples from the mean. #Then we add the differences up. sumofsquares = sum(diffobj1_sq, diffobj2_sq, diffobj3_sq, diffobj4_sq, diffobj5_sq, diffobj6_sq, diffobj7_sq) #Divide the sum of squares by n - 1. variance = sumofsquares/(n-1); variance ## [1] 7.47619 Why n - 1 instead of n? One reason is that, theoretically, because we are taking the mean of a sample, rather than all individuals, we underestimate the variance, so taking n-1 corrects that bias. Consider it a penalty for measuring a sample, not the entire population! Another practical reason is that dividing by n-1 makes the variance of a single sample undefined (unsolvable) rather than zero (solvable) For standard deviation, we just take the square root of the variance, to remove the effect of squaring the differences when calculating the variance, and thus contextualizing our estimate of variation with regard to the mean. For example, the variance for the Sedona population is 7.48, larger than the sample mean of 5.12; while the standard deviation is 2.73, indicating that you would expect most observations to be 5.12 +/- 2.73 (we’ll get to quantiles in a minute). The formula for standard deviation is: \\(\\sigma = \\sqrt\\frac{\\Sigma(x_i - \\mu)^{2}}{n - 1}\\) where \\(\\sigma\\) is the sample variance; \\(\\mu\\) is the sample mean; \\(x_{i}\\) is the value of one observation; \\(n\\) is the number of observations. Finally, standard error and confidence intervals (we’ll get to confidence intervals later) are the most common metrics of variance presented in journals. The formula for standard error is: \\(SE = \\frac{\\sigma}{\\sqrt n}\\) where \\(SE\\) is standard error of the sample; \\(\\sigma\\) is the standard deviation; and \\(n\\) is the number of samples. Why do we divide the standard deviation by the square root of the sample size to get standard error? While standard deviation measures the variation of the sample, standard error is meant to estimate the variation of the entire population of samples, if we could measure all individuals accurately. By dividing by the \\(\\sqrt n\\), the larger the sample size, the lower the error, because you have a more complete estimate of the true mean. In other words, standard deviation is just a measure of the variation of our sample, while standard error also incorporates information about our sampling process (how many individuals we have sampled). Want to delve deep into standard error and deviation (me neither - ha)?: Google central limit theorem + standard error / standard deviation. Means and variance measures are the most common way to describe quantitative data. However, several other metrics are useful for understanding the nature of your data and making decisions about analyses. A comprehensive understanding of your dataset includes describing these four features: Location (Mean, Median) Spread (Variability) Shape (Normal, skewed) Outliers We’ve talked about means. The median is just the central number in the dataset, and helps you identify skewness. #an example of an unskewed population sedona_unskewed &lt;- c(1, 2, 3, 4, 5, 6, 7) mean(sedona_unskewed) ## [1] 4 median(sedona_unskewed) ## [1] 4 #previous sedona population; skewed sedonapopulation &lt;- c(3, 3, 3, 3, 7, 8, 9) mean(sedonapopulation) ## [1] 5.142857 median(sedonapopulation) ## [1] 3 In an unskewed population, the mean will equal the median. Skew may not seem important, but it has statistical ramifications, AND it tells us something meaningful about the data. For instance, what if I said that mean price of a home in Flagstaff is 350K, but the median price of a home is 300K? We would know the that average house prices are driven up by a smaller number of expensive homes. We can quantify skew by comparing means and medians (mean &gt; median = right-skewed; median &gt; mean = left-skewed), but it is helpful to visualize the shape of data with a histogram. A histogram is a graph of the frequency of different measurements. Let’s add a few more observations to our Sedona populations (skewed and unskewed) and check out the look of the data! sedona_unskewed &lt;- c(7, 2, 2, 3, 3, 3, 3, 6, 6, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 0.5) mean(sedona_unskewed) ## [1] 3.975 median(sedona_unskewed) ## [1] 4 #I&#39;m renaming sedonapopulation, sedona_skewed for this example sedona_skewed &lt;- c(3, 3, 3, 3, 7, 3, 4, 5, 6, 3, 3, 3, 4, 4, 6, 7, 8, 9, 3, 4, 5, 2) mean(sedona_skewed) ## [1] 4.454545 median(sedona_skewed) ## [1] 4 hist(sedona_unskewed, main = &quot;Mostly Unskewed&quot;, xlab = &quot;Plant height (cm)&quot;, breaks=5) In this relatively unskewed example, the tails are approximately even. This shape is also referred to as a normal or Gaussian distribution. h &lt;- hist(sedona_unskewed, main = &quot;Mostly Unskewed&quot;, xlab = &quot;Plant height (cm)&quot;, breaks=5) xfit &lt;- seq(min(sedona_unskewed), max(sedona_unskewed), length = 40) yfit &lt;- dnorm(xfit, mean = mean(sedona_unskewed), sd = sd(sedona_unskewed)) yfit &lt;- yfit * diff(h$mids[1:2]) * length(sedona_unskewed) lines(xfit, yfit, col = &quot;black&quot;, lwd = 2) Here, we superimposed the bellshaped Normal or Gaussian distribution. hist(sedona_skewed, main = &quot;Skewed&quot;, xlab = &quot;Plant height (cm)&quot;, breaks = 5) In this example of skewed data, the tail tapers to the right, indicated that the data is skewed to the right. In order to explain outliers, we need to look at quantiles! Quantiles are proportions of your data, in other words a way to break your data into chunks to understand spread. You can break your data into as many quantiles as you would like, but it is most common to break your data into 4 parts, also called quartiles. (If you break data into 5 parts, the components are called quintiles, 10 parts = deciles, 100 parts = percentiles). When you break data into quartiles, roughly 25 percent of the data occurs within each data chunk. The first chunk of the dataset contains 25% of the data (25th percentile; 25% of the data fall at or below this cut-off) is called the first quartile, the 50th percentile is called the sample median or the second quartile, the 75th percentile is called the third quartile. Box and whisker plots are commonly used to quickly examine quartiles. Let’s check out our plant height data again, using a box and whisker plot. In the plot shown here, the box encapsulates the Interquartile Range (IQR); the center of the data ranging from the 25th percentile to the 75th. The black line in the middle of the box is the median (also called the 50th percentile, because it bisects the dataset; half of the data occur above the median and half below). The lines emerging from the box (whiskers) indicate the extent of the first and third quartiles, and usually corresponding with the minimum and maximum values of the dataset, unless there are outliers. An outlier is a datapoint that occurs outside of the 1st or 3rd quantile. Let’s add one to our Sedona dataset, and see how it is represented on the box and whisker plot. #Let&#39;s add a plant height of 20. sedona_skewed &lt;- c(3, 3, 3, 3, 7, 3, 4, 5, 6, 3, 3, 3, 4, 4, 6, 7, 8, 9, 3, 4, 5, 2, 20) boxplot(sedona_skewed, main=&quot;Skewed&quot;, ylab=&quot;Plant height (cm)&quot;) The outlier appears as a dot on the box and whisker plot, and is the maximum value of the dataset. One other thing to note: Standard deviation also breaks data into meaningful segments, but is only used when data conform to a normal distribution; the mean +/- 1 SD accounts for 68% of the data, +/-2 SDs contains 95% of data, and +/- 3SD includes 99% of data. That said, I’ve never presented standard deviation in a manuscript; it is much more common to include standard error or confidence intervals (discussed later). 3.5 Figures Figures are a common way to show key elements of your data or statistical analysis. In this tutorial, you’ve seen both histograms and box plots (aka box and whisker plots). When presenting results in a scientific manuscript or report, figures will be accompanied by figure legends. A good figure legend provides the following information: 1. A description of what the figure is showing you. 2. For complex figures with multiple panels, an orientation to the structure of the figure 3. Explanation of any symbols, colors, and/or lines 4. Description of how variance is quantified 5. Definitions of axes or units, if unclear 6. Acknowledgment of data source, if data source requires attribution 7. Implications of the figure (optional) Here is an example figure legend of a hypothetical figure showing species richness as a function of temperature across ecosystems: Figure 1. Species richness increases with temperature across ecosystems. Panel A shows the mean species richness across three ecosystems: grassland (green), forest (blue), and desert (orange) from 2015 to 2020. Panel B depicts the temperature variation in these ecosystems during the same period. Circles represent data from 2015, while triangles represent data from 2020. The x-axis shows mean annual temperature (°C), and the y-axis shows species richness (number of species per 1000 m²). Error bars indicate ±1 standard deviation. The dashed line represents the best-fit linear regression (R² = 0.85, p &lt; 0.05), showing a positive correlation between temperature and species richness. 3.6 Summary We’ve played around a lot with data, but what do you actually need to take away from this? 1. Understand data types (Categorical, Numerical discrete, Numerical continuous, Ordinal) 2. Know ways to describe numerical continuous data (Location, Spread, Shape, Outliers).. 3. Be able to calculate mean, median, and standard error. 4. Familiarize yourself with mathematical annotation. 5. Familiarize yourself with R code. 6. Be able to interpret a histogram and box-whisker plot. 7. Be able to construct an appropriate figure legend. 3.7 Assignment Now, let’s play around a little more with R! For your reference, here is a guide that shows the basics formulas for calculations in R: Supplementary Material Let’s also try describing the petal lengths of 3 different plant species: Milkweed, Bluestar and Pectis using this dataset: Download the example dataset The code can be used to import the data, but in case you wanted to access the data yourself - provided above! Build on this code, to generate your description of the petal lengths of your focal species: R Script for Chapter 1 Please put your results in a document and submit to your TA in canvas! Be sure to include: 1. Summary statistics for your flower species (mean, median, and se) 2. Plots that you create 3. Appropriate figure legends for each plot, including a description of the data that a box plot shows. "],["natural-selection.html", "Chapter 4 Natural selection 4.1 Background 4.2 Downloads for this class 4.3 Objectives 4.4 Research question: 4.5 Methods 4.6 What to turn in", " Chapter 4 Natural selection 4.1 Background The living world is rich with diversity. This diversity is often examined at the level of species, with over 1.5 million species described and estimates of the total number of species on Earth ranging from 5 to 100 million (estimates vary greatly; see figure below). Yet diversity also exists within species, populations, social units, and family lineages. Variability in the features of organisms that we see today is put into even greater perspective when one considers the vast amount of diversity that occurred in previous generations. Only a fraction of this remains recorded in the fossil record. Fossils suggest that the number of species has increased over time, although some relatively brief periods of decrease are also recorded. Records also suggest that characteristics have become more complex over time. There are numerous hypotheses that could explain the origin and diversification of species. Some attribute it to divine intervention, some to extraterrestrial influence, and still others to simple physical and chemical processes that occurred in our primordial backyards. Regardless of what caused the origin and initial diversification of life, ecologists are generally curious about the sources of diversity within modern populations, and knowing what causes this diversity to be maintained, increased, or eliminated from populations. Indeed, the entire field of conservation biology is devoted to understanding and preserving natural variation within and among groups of organisms. Key Terms: (you’ll want to be sure to use these in your lab report!) Natural selection: the process by which organisms better adapted to their environment are able to survive for longer and produce more offspring. Fitness: an organism’s relative likelihood of surviving long enough to pass on its genes. In other words, those who contribute most to the next generation exhibit the highest fitness. Selective environment: an organism’s environment plays a role in selecting favorable traits, and traits that get selected for may be different depending on the nature of each environment. Selective agent: a biological or physical agent that imposes selection, and thereby determines which individuals pass on genes and which do not. 4.2 Downloads for this class Download the CSV file Download the R file 4.3 Objectives To understand how natural selection operates and characteristics within and among populations change over time, and to answer the following research question (especially in your lab report): 4.4 Research question: Does the selective environment affect the composition of future generations? 4.5 Methods Materials Each group of three should have: 1 piece of patterned fabric 7 different colors of dots (approximately 80 of each color, kept in separate piles) Green bowl (for discarding dots) Note-taking materials Procedure With your group members, read through the entire procedure. Based on what you now know about the experiment, formulate a hypothesis. Write it down for inclusion in your lab report. Each group of three to four should select a fabric pattern of its choice (it’s OK if two or more groups use the same pattern) and get seven piles of differently colored paper dots (keep colors separate; colors include black, hot pink, green, pink/peach, dark yellow, white, blue). Count out 12 dots of each color, and mix them in a single dish. Spread the fabric flat on a table and randomly sprinkle the 84 dots onto the fabric. Be sure to disperse the dots all over the fabric, not just in a small group on one part of the fabric. On the spreadsheet provided here, record the frequency of each type of colored dot. Imagine each group member is a red-tailed hawk, and that each colored dot is a mouse with a particular fur color. Each mouse runs free in its respective environment, while each hawk preys on the mice. Hawks can only prey on one mouse at a time. A hawk must “fly” the mouse back to its nest (another culture dish) each time it captures one. The hawks must hunt quickly – you will only have 45 seconds to remove 56 mice! In the first year of predation, the hawks remove 56 mice from the population (thus, 28 mice remain in the population). Group members will remove the first 56 dots they see in 45 seconds. If you need more than 45 seconds, keep going until you remove 56, just try to go as quick as you can while following the instructions! Remove the 28 survivors from the fabric as well. Each of the survivors “overwinters” and has two offspring of the same color. Count out these new mice and incorporate them into the population. [If this requires hole-punching more of a particular color, feel free to do so.] After they’ve been incorporated, record the frequency in Table 1 of each fur color in the population (note: the population size after the new mice are incorporated should again be 84, but the frequencies of the fur colors might be different than those recorded in Step 4 of this investigation). Again, randomly sprinkle the 84 dots onto the fabric. Repeat Steps 6 -8 three times, recording the frequency of fur colors for each generation. After the third iteration of hawks preying on the population, count the remaining mice (those that would make up the fourth generation) and record in Table 1. Next to your first graph, make a bar graph showing the frequency of each type of colored dot in the final generation. Copy the two graphs into your lab report. Compare the frequencies of fur colors (dot colors) in the first generation to those in the fourth generation. If the frequencies of fur color changed in the population over time, then within your group and with everyday language describe the phenomenon that was responsible for the change. Graph your results using the R file that you downloaded 4.6 What to turn in Lab Report Due in 1 week on Canvas Your final product will be a lab report containing only research question, hypothesis, methods, and results (Format 1) as described in the “Written Lab Report Guidelines” on Canvas. Only use the data from your group of hawks and habitat. Compare the distribution of mice fur colors between the first, second, third and fourth generation to answer the research question and address how your results aligned with your hypothesis. Describe your data collection methods (outlined above) and your results. You must include one table and one set of figures based on today’s results. Next week, you will turn in a completed lab report to your instructor through Canvas in which you have made your best effort to write up those components of a lab report. Then, your instructor will provide you with feedback by the following week’s class. "],["population-ecology.html", "Chapter 5 Population ecology 5.1 Lab set-up (week 1) 5.2 Maintaining your microcosms and measuring population growth (week 2) 5.3 Final data collection and analysis (week 3) 5.4 Assignment", " Chapter 5 Population ecology 5.1 Lab set-up (week 1) In a few weeks, we will complete a lab on the population dynamics of duckweed (Lemna minor) in microcosms. Today, we will set up your experiment. Next week, you will collect data on your populations and maintain your experiment. 5.1.1 Downloads for this lab Download the CSV file Download the R file 5.1.2 Objectives To investigate population dynamics of duckweed using microcosms. 5.1.3 Materials Microcosms (i.e., clear plastic containers) Lemna minor individuals Water Small labels or markers Light source (natural sunlight or artificial light) Data recording sheets First, we will explore growth rates of populations with two different initial population sizes. Working in groups of 3 – 5, follow the procedure below. Then, proceed to setting up your experiment in which nutrient levels are varied! 5.1.4 Procedure Fill two microcosms with artificial pond water, 200 ml. Mark the 200 ml water level on the cup so that you can refresh the culture solution to the same volume. Place two healthy Lemna plants in one of the cups. Place 15 health Lemna plants in the second cup. Because a plant can consist of one or more thalli, it is necessary that you now count the number of thalli in each cup. One thallus is any leaf unit that is over 1.5 mm. Record these data in the Day 0 column of Table 1. Place the cups under fluorescent or near natural lights for a period of two weeks, check them periodically to refill the cups to the 200 ml line. Count the number of thalli in each cup on Day 7 and Day 14. These counts are already reflected in the datasheet for this lab, but you will need to record population size going forward Here is some information on L. minor to assist you! 5.2 Maintaining your microcosms and measuring population growth (week 2) Check the microcosms and refill the cups to the 200 ml line. Count the number of thalli in each cup on Day 7 and Day 14. Record these data in the population size column of your datasheet. 5.3 Final data collection and analysis (week 3) In this lab, we will collect data from your microcosms and analyze your results. First, we will learn a little more about microcosm studies in ecology, your model organism, and some population ecology background. 5.3.1 Microcosm studies of population dynamics Microcosms in ecological sciences are small-scale experimental systems that replicate natural ecosystems. Researchers use microcosms to study ecological interactions, nutrient cycling, and other ecological processes in a controlled environment. Here we will use microcosms to examine population dynamics of duckweed (Lemna minor) to gain insights into core concepts in population ecological, such as population growth and carrying capacity. In class, we discussed how populations have the capacity to grow exponentially, but resource availability eventually limits population growth. Light, space and nutrients are all examples of resources that may be limited within ecosystems and constrain population growth. Here, we will explore populations growth using the model species, L. minor. A model organism is a species used in scientific research to represent a broader biological phenomenon, serving as a convenient and well-understood subject for studying fundamental biological processes. Over the last few weeks, you have been establishing and maintaining microcosm experiments with duckweed (experiment modified from Population growth: Experimental models using duckweed (Lemna spp.); University of Toronto, Toronto CANADA). Few plants are suitable for studying continuous population growth because most plants have life cycles with discrete jumps in population size, their reproduction is seasonal and they respond to changes in population density by changing size and shape instead of population number (Harper, 1977). However, free-floating aquatic plants such as duckweeds (Lemna spp) or water ferns (Azolla and Salvinia) undergo continuous growth and therefore are excellent models for quantifying aspects of population growth (Clatworthy and Harper, 1962; Harper, 1977). These plants are stemless and have only one to four leaf-like structures called thalli (singular = thallus), if they are flowering plants, or fronds, if they are ferns. Roots from the thallus hang free in the water. Duckweeds can reproduce by flowering and setting seed (sexual reproduction) but seldom do. More commonly they reproduce asexually by producing a new thallus or frond directly from an old one. When a new thallus has grown large enough and has roots, it breaks loose from its parent plant and grows on its own as a separate plant. The growth of a population can be followed by counting thalli or measuring changes in biomass (dry weight). If a pond or lab beaker is inoculated with one or two thalli and conditions are favorable, the plants commence exponential growth (Fig. 1, Phase I). The growth rate of the population under these conditions is density independent; the population grows unimpeded by resource limitation or competition. We can estimate the intrinsic rate of growth (r- see the equations on following pages) by measuring the uninhibited growth of low-density populations. As thalli accumulate, the population becomes crowded and limited by the available resources. For a period, growth appears constant (Fig. 1, Phase II) as the width and thickness of the mat of floating plants increases. Eventually the beaker or pond fills with floating plants (Fig. 1, Phase III) and the population reaches a steady state (see the following equations). At this point, for every new thallus that appears, an existing one is shaded and dies, i.e., the population size is stable. The logistic growth curve (Fig. 1) illustrates all three Phases. 5.3.2 Population dynamics basics Using your own or class data (if your experiment has failed), graph the average (mean) number of thalli (N) as a function of time for the cultures that started with two plants and the cultures that started with 15 plants. The three equations shown below describe growth of populations: Exponential population growth (expressed by the instantaneous rate of increase, r): \\[ \\frac{dN}{dt} = rN \\] where: - \\(N\\) is the population size, - \\(r\\) is the intrinsic growth rate, and - \\(t\\) is time. When we are looking over a discrete period of time, we can calculate Geometric population growth rate, described by the equation: \\[ N(t+1) = N(t) e^{rt} \\] where: - \\(N(t)\\) is the population size at time \\(t\\), - \\(r\\) is the intrinsic growth rate, and - \\(t\\) is time. - \\(e\\) is the base of the natural logarithm (constant) The factor by which a population increases in one unit of time (ert) is the finite growth rate of the population (λ), from: \\[ N(t+1) = N(t) e^{rt} \\] We take the natural logarithm of both sides: \\[ \\log N(t) = \\log N(0) + rt \\] This equation now represents a linear relationship between \\(\\log N(t)\\) and \\(t\\), where: - The slope of the line is \\(r\\) (the intrinsic growth rate), - The intercept is \\(\\log N(0)\\) (the log of the initial population size). By plotting \\(\\log N(t)\\) vs. time \\(t\\), the slope of the line provides a direct estimate of \\(r\\). When resources are finite, we can rearrange the exponential growth equation to include the carrying capacity of the environment. The logistic growth model, which accounts for a population’s carrying capacity, is described by the equation: \\[ \\frac{dN}{dt} = rN\\left(1 - \\frac{N}{K}\\right) \\] where: - \\(N\\) is the population size, - \\(r\\) is the intrinsic growth rate, - \\(K\\) is the carrying capacity, and - \\(\\frac{dN}{dt}\\) is the rate of change of the population over time. Estimating geometric growth Let’s start by plotting population growth through time. Since population growth rate is exponential, we can plot it as log (N) over time. Plot log N as a function of t for the cultures that started with two plants. The slope of a line drawn through the mean log N at Day 0, Day 7, and Day 14 would approximate r. Make the same graph and calculations for the cultures that started with 15 plants. Now, let’s calculate the finite rate of increase, \\(\\lambda\\), using the equation: \\[ \\lambda = \\left( \\frac{N_{t+1}}{N_t} \\right)^{\\frac{1}{t}} \\] where: - \\(N_{t+1}\\) is the population size at the final time point (e.g., Day 14), - \\(N_t\\) is the population size at the initial time point (e.g., Day 0), and - \\(t\\) is the total time (e.g., 14 days). As the population of Lemna in your cup grows, the rate of growth will slow down. When the population reaches the carrying capacity of the cup, the growth rate of the population will be 0 (dN/dt = 0). If you plot the geometric growth rate (λ, calculated above) for each cup, as a function of population size (Nt), you should have a linear plot where the y intercept (where N = 0) would approximate r and when λ = 1, n = K. We derived that information by rearrange your formula for carrying capacity: Estimating \\(r\\): - The intercept of the linear model (where \\(N = 0\\)) is an approximation of the intrinsic growth rate \\(r\\). Estimating \\(K\\): - The carrying capacity \\(K\\) is estimated by solving the equation where \\(\\lambda = 1\\) (i.e., when the population growth rate reaches zero): \\[ K = \\frac{1 - \\text{intercept}}{\\text{slope}} \\] Plot your data. What is your estimated carrying capacity (K)? 5.4 Assignment Please turn into your TA, your: 1. Estimates of r for both populations &amp; associated figure 2. Estimates of finite population growth 3. Estimate of carrying capacity &amp; associated figure 4. Summarize the findings and draw conclusions about the factors influencing population dynamics and discuss the implications of the study for understanding population ecology in natural ecosystems. Be sure to describe any differences in growth rates between the two microcosms and discuss why you might be seeing that pattern. "],["invasive-species.html", "Chapter 6 Invasive species 6.1 Introduction 6.2 Downloads for this lab 6.3 Objectives 6.4 Materials 6.5 Procedure 6.6 Assignment", " Chapter 6 Invasive species 6.1 Introduction In this lab, you will consider the distribution of a non-native species that has become widespread in our region. You will collect field vegetation data according to common methods in ecology and answer discussion questions after your data collection. We will be meeting near the South Commuter Lot / Disc Golf Area on campus for this lab. Download location information Biological invasions are considered one of the primary threats to biodiversity and ecological functions today. Any species that has been introduced by humans (either accidentally or on purpose) to a location it didn’t reach on its own is considered a non-native species. Other terms you might hear include exotic and alien. A non-native species that exerts a negative impact on native species is termed invasive. Not all non-native species become invasive: in fact, it is estimated that out of all species that are introduced, about 10% are able to establish reproducing populations in place, about 10% of those escape human-dominated areas and spread through natural areas, and about 10% of those become invasive. Figure 1 illustrates the phases of invasion. As non-native species establish and spread, their populations tend to follow predictable growth patterns. An initial group of individuals will reproduce and demonstrate population growth in the immediate area, slowly expanding the infestation as shown in Figure 2. Occasional long-distance dispersal events will establish new populations, each of which then demonstrates the same process and expands its occupied area. Invasive species are known to exert a range of impacts, depending on the invading organism and on the characteristics of the invaded system. Worldwide, invasive species include vertebrates, invertebrates, and plants. Invasives have been known to outcompete native species, reducing native biodiversity in the invaded locale. Thick infestations of invasive plants, where no native plants are able to persist, are known as monocultures. Other invasives act as predators or herbivores, directly damaging or preying upon native species. Such effects have resulted in extinction (for example, predation by invasive cats and rodents has resulted in extinction of ground-nesting birds on islands). Other invasive species transform ecological conditions or functions: for example, invasions may alter soil pH or stability, water table accessibility, pollinator abundance, etc. Agencies that manage forests and other natural areas must survey and monitor invasive plants within their jurisdictions. Monitoring information that is collected includes: total area infested, density or cover of the infestation, spread rate from year to year, environmental characteristics of inhabited sites. This information can help agencies predict further spread in the future. Other information that is often collected is focused on understanding the impacts of the invader, including the implications of the infestation for native species, soil characteristics, moisture availability, and ecological functions such as species interactions. In this lab, we will look at where a non-native species of your choosing occurs, measure its density, and evaluate the presence of young individuals in order to develop some inferences about likely spread rates. 6.2 Downloads for this lab Download random number sheet Download the CSV file Download the R file 6.3 Objectives To characterize the current infestation of your nonnative focal species near a recreation site between NAU’s campus and a 4-lane interstate highway, and see how this infestation is driven by disturbance to the landscape. 6.4 Materials Each group of 4 or 5 should have: 1 Tape measure (50m) 1 meter tape (or meter stick) 16 Pin-flags Printed lab with datasheets Website for identifying invasives: https://nazinvasiveplants.org/ 6.5 Procedure 6.5.1 Hypothesis development In this lab, we will be characterizing a nonnative species infestation at our study site and exploring where it occurs. Specifically, we are interested in the question: Does disturbance increase the abundance of nonnative species? Look around the site. Considering the site characteristics you can observe, brainstorm with your group and write a hypothesis for how you think environmental conditions are affecting the distribution of your nonnative focal species in the area. Record your hypothesis - you will need it for you lab packet! Now, what evidence will you need to accept or reject your hypothesis. Write an if/then statement to guide your work, again recording for your lab packet. Several things to know when you are writing your if/then statement, we will be measuring non-native species density as your response variable. You will be recording both evidence of disturbance (i.e., roads, trash, etc.) as a direct measure of disturbance, and tree cover as an indicator of undisturbed habitat. 6.5.2 Nonnative species density quadrats You will set your quadrats up along transects, or linear sampling features that you create with a tape measure or transect tape. Since you suspect that azimuth, or the direction, could influence nonnative species behavior, you decide to establish 4 transects, and place 4 quadrats along each transect. You divide the field into general directions. Azimuth is measured clockwise from 0° (which corresponds to true north) up to 360°. - 0° or 360° = North - 90° = East - 180° = South - 270° = West At each end, use this random number sheet or the random number generator on your phone (you will need to choose smaller numbers) to identify a starting point for your transect. As an example, go to the northern part of the field, place your finger anywhere along the random number table. Use only the first two numbers of the 5 digit number. This will indicate the number of paces you will take along the northern end of the field. Then run the transect from the starting point south (north to south; see Fig. 3). Extend the transect tape 50 meters to the south, in a line roughly parallel to the fence on the west side of the study site. You will sample four 4x4m quadrats along this 50m transect: one starting at 0m, one starting at 15m, one starting at 30m, and one starting at 45m. At each survey point, place a pin-flag there to mark the corner. Continue 4m further down the transect tape and place another pin-flag. Use your meter stick/tape to measure 4m to the east of each of those pin-flags and place another pin-flag at each resulting point, creating a 4x4m quadrat. Within a quadrat, count the total number of your nonnative focal species plants and record that number. Record the total number of your nonnative focal species plants in the column ‘NumberNonNativeSpecies’ in this datasheet. In addition, walk carefully throughout that 4x4m quadrat and look for evidence of disturbance (e.g., animal waste, trails, trash, scat, etc.). If there is disturbance in your plot, record ‘Yes’ if there is no disturbance record ‘No’ (be sure to capitalize) in this column, ‘DisturbancePresent’. As evidence of more intact habitat (less disturbed), also record the number of trees (taller than the height of the tallest member of your group) that are shading the quadrat in the column, ‘TreeNumber’. Repeat all of these methods until you have gathered data for all four 4x4m quadrats along all 4 transects (You will have collected data from 16 quadrats). 6.5.3 Analyses Once you collect your data and enter it into your csv file, analyze your data using your R file. We are going to conduct a statistical test on your data using linear models. A linear model is a mathematical method used to describe the relationship between one or more predictor variables (also called independent variables) and a response variable (also called the dependent variable). When we fit a linear model, we want to know if the relationship between the predictor variables and the response variable is statistically significant. This helps us determine whether the predictors have a meaningful effect on the response, or whether the observed relationships could just be due to chance. 6.5.3.1 1. Hypothesis Testing for Each Coefficient For each predictor in the model, we test the following hypotheses: Null Hypothesis (\\(H_0\\)): The coefficient is zero, meaning the predictor has no effect on the response variable. Alternative Hypothesis (\\(H_A\\)): The coefficient is not zero, meaning the predictor does have an effect on the response variable. 6.5.3.2 2. P-value The p-value tells us the probability of observing the data, assuming the null hypothesis is true. For each predictor: - A small p-value (typically \\(&lt; 0.05\\)) suggests that the predictor has a significant effect on the response variable, and we reject the null hypothesis. - A large p-value (typically \\(&gt; 0.05\\)) suggests that the predictor does not have a significant effect, and we fail to reject the null hypothesis. 6.5.3.3 3. F-statistic (Overall Model Significance) The F-statistic tests whether the model as a whole is better than a model with no predictors (a model that only includes the intercept). This tests the null hypothesis that all the coefficients (except the intercept) are zero: - A significant F-statistic (p-value \\(&lt; 0.05\\)) suggests that the model explains a significant portion of the variation in the response variable. 6.5.3.4 4. R-squared The R-squared value tells us how much of the variation in the response variable is explained by the model. While this isn’t a test of significance, a higher \\(R^2\\) value indicates that the model fits the data better. 6.5.3.5 5. Reporting your results A results statement has several important components: 1. A description of the statistical results with an appropriate citation on your results (test statistic, p-value). 2. If you have a statistically significant effect, a description of the magnitude and/or direction of the relationship, which often cites a figure. Here is an example of what your results statement should look like: The position of the transect affect nonnative species density (F = 3.45, p = 0.02). Quadrats located on the southern side of the field had higher levels of invasion (Fig. 1). 6.6 Assignment When you are finished, report out on the primary research question that we addressed in lab: Does disturbance affect non-native plant density? In your brief report, provide: 1. Your hypothesis for the question 2. Your if/then statement describing the patterns that you expect to see in order to identify the information that you need to gather 3. A results statement for each statistical test 4. A figure with an appropriate legend 5. Interpretation of your results, answering the question: Does disturbance affect non-native plant density? Did you support or refute your hypothesis? Put this in a document and turn into your TA! "],["water-quality.html", "Chapter 7 Water quality 7.1 Background 7.2 Key Water Quality Terms and Concepts 7.3 Water Quality Monitoring: 7.4 Downloads for this lab 7.5 Hypothesis generation 7.6 Methods", " Chapter 7 Water quality 7.1 Background Stream ecology is best understood in the contexts of physicochemical and biological processes. The physical properties of streams include the slope, aspect, elevation and temperatures of the stream environment. The chemical properties of streams include a large set of characteristics; such as alkalinity, pH, nutrients - such as nitrogen and phosphorus, and the gasses dissolved in stream waters, including dissolved oxygen. In this lab we will collect water samples at Francis Short Pond in order to document effects of Rio de Flag Flood Control Project on water quality to be compiled over time and provided to the City of Flagstaff [Download the PDF Map to get to Francis Short Pond]. We will evaluate the current water quality of Francis Short Pond to determine whether it falls within standards established by environmental protection agencies worldwide. 7.1.1 History of Francis Short Pond Some people think Frances Short Pond began as a water storage pond for the Santa Fe Railroad’s steam trains. In the 1920s a dam was built upstream on the Rio de Flag to create a swimming and skating area. But over time the area got filled with trash, sediment and street sweepings dumped in by the city. About 40 years ago (in the late 60s), the city of Flagstaff was considering paving over the pond and making it into a parking lot. At the time, Aztec Street ran right beside the pond’s banks, connecting Cherry Avenue and North Thorpe Road. A local teacher rallied support and convinced the city council to preserve Frances Short, then worked with students to plant cottonwoods, Bebb willows, and junipers near the pond’s banks and create the island in the middle of the water. In more recent years high vegetation levels (algae, bulrushes etc.) have affected water quality, habitat, and recreational and educational uses of the pond. The city underwent one major restoration project in 2005 where it drained the pond and dredged it. That grant project also added a sediment cleanout area, a small spillway and a wetland to filter some of the storm runoff that enters the pond. An aeration system helps keep the pond livable for fish and other wildlife. The city completed a similar process in 2015, removing vegetation and restoring the trail around the pond. The overgrown vegetation is a problem because during the times when those plants aren’t photosynthesizing, such as at night or when the pond is covered in ice, they respire, pulling oxygen from the water. That lack of oxygen has caused fish die-offs in recent years. The Arizona Department of Game and Fish regularly stocks the pond with hundreds of pounds of catfish, largemouth bass and bluegill sunfish. The pond also has nonnative Siberian elm and Russian olive trees that volunteers have tried to address in the past. The pond is supplemented with reclaimed water (in addition to whatever comes down the Rio de Flag channel). 7.1.2 Rio de Flag Flood Control Project The Rio de Flag Flood Control Project is a large-scale infrastructure initiative in Flagstaff, Arizona, aimed at reducing the risk of flooding in the area, particularly in downtown Flagstaff and the Southside neighborhood. The project was developed in response to the recurring flood risks posed by the Rio de Flag, a waterway that runs through the city and is prone to flooding during heavy rain events. Purpose: To mitigate the flood risks for over 1,500 structures, including homes and businesses, and prevent potential damage estimated in the millions of dollars. Scope: The project includes upgrading stormwater infrastructure, creating detention basins, and improving the flow capacity of the Rio de Flag channel. Partners: The project is a collaboration between the City of Flagstaff and the U.S. Army Corps of Engineers. Status: While portions of the project have been completed, such as some channel improvements, the full implementation has been delayed due to funding and design challenges. Full completion is expected to significantly reduce the risk of flooding in Flagstaff. Francis Short Pond plays an important role in the Rio de Flag Flood Control Project, including: 1. Stormwater Retention: Francis Short Pond helps capture stormwater runoff from nearby areas, acting as a retention basin. This helps reduce the volume of water flowing into the Rio de Flag during heavy rain events, contributing to flood control by temporarily storing excess water. 2. Flood Mitigation: The pond reduces the pressure on the Rio de Flag’s natural channel by holding stormwater, which helps manage water flow and reduce the risk of downstream flooding. By retaining stormwater, it lowers the volume of water that reaches the Rio de Flag during peak rain events, which is crucial in preventing flood events in urban areas like downtown Flagstaff and the Southside neighborhood. 3. Water Quality Improvement: The pond can help improve city water quality by acting as a buffer zone for sediments and pollutants before they enter the Rio de Flag system. As a retention basin, it allows suspended sediments, nutrients, and pollutants to settle out of the water column, preventing them from being washed downstream into more sensitive areas. Given this, how do you think Rio de Flag Flood Control Project will affect the water quality at Francis Short Pond? 7.2 Key Water Quality Terms and Concepts Dissolved Oxygen (D.O.) – Oxygen that is dissolved in water; the most important indicator of water body health for the support of aquatic ecosystems. Effluent – Wastewater (sewage) that has been treated at a wastewater treatment plant. In the US, treated effluent is discharged. Nitrate(NO3-)– a nitrogen-containing organic molecule that is found in fertilizer and can be readily used by plants; excess nitrate in water can cause eutrophication. Other sources of nitrates include municipal and industrial waste water, septic tanks and private sewage disposal systems, urban drainage and decaying plant debris. Phosphate(PO4-)– a phosphorus-containing organic molecule that is derived from rocks or detergents; excess phosphate in water can cause eutrophication. Because phosphorus tends to attach to soil particles, it moves into surface-water bodies as a result of erosion and runoff into the water. pH– a measurement of how acidic or basic a solution is; technically, it is the concentration of hydrogen ions (H+) in a liquid. Perfectly neutral = pH of 7. Natural changes in pH occur with interactions between the water source and surrounding rock. pH can also vary with precipitation (especially acid rain) and wastewater or mining discharges. Total dissolved solids (TDS) - inorganic salts (principally calcium, magnesium, potassium, sodium, bicarbonates, chlorides, and sulfates) and some small amounts of organic matter that are dissolved in water. High TDS readings can be the result of water running through a region that has rocks with a high salt content. Human-caused sources include agricultural and urban runoff, wastewater discharges, industrial wastewater and salt that is used to de-ice roads. 7.3 Water Quality Monitoring: The Environmental Protection Agency (EPA) and the Arizona Department of Environmental Quality (AZDEQ) set safe levels for naturally-occurring chemicals and contaminants in Arizona’s waters. Water quality standards exist for drinking water, surface water, and wastewater effluent and vary depending on the water source and the intended use. Of the three sets of standards, drinking water standards are the strictest. The EPA currently regulates approximately 90 contaminants that occur in drinking water but adds to the list of regulated contaminants as we learn more about the effects of various chemicals on human health. Water is perhaps our most precious natural resource in the arid Southwest. High-quality water is important in many aspects of our lives, from providing cities and towns with clean drinking water to supporting native fish and other wildlife species in rivers and creeks found in the region. 7.4 Downloads for this lab 7.5 Hypothesis generation The research question for this lab is: Does the current water quality in the wash fall within standards established by environmental protection agencies worldwide? Given what you know about Rio de Flag Flood Control Project, generate a hypothesis to the research question. How will you know if your hypothesis has been proved correct? Write an if/then statement! 7.6 Methods Divide into four groups, and make sure that the backpack kit that you have has instructions for each of the tests listed below. nitrate (N) phosphorus (P) stream water temperature (T) stream water pH (pH) dissolved oxygen (dO) total dissolved solids (TDS) STEP 1: GET NITRILE EXAM GLOVES FROM YOUR LAB INSTRUCTOR BEFORE HANDLING ANY CHEMICALS After you have the necessary number of gloves, carefully follow the instructions for each water quality test, detailed on the laminated cards. It is a good idea to read over the instructions for each test before you run the test, to make sure you don’t forget or miss any steps. Gather all solid waste into the black trashbag provided, and place all liquid waste into the appropriately labeled waste bottles provided – it is very important that we remove all chemicals and trash from the pond so that we are not contaminating the environment. Data Table Record the results of your tests below. Compare your results with other groups to ensure you all conducted the tests properly. If your numbers are way off, consult with your lab instructor. Francis Short Pond Water quality standard for US aquatic ecosystems Nitrate (N) &lt;41 ppm Phosphorus (P) &lt;10 ppm Water temperature (T) varies Water pH (pH) 6.5-8.5 Dissolved Oxygen (dO) 4-8 mg/L Total Dissolved Solids (TDS) &lt;450 mg/L Now, compare the results you found with the global water quality standards in the right hand column of the table. Is the Francis Short Pond water within standard ranges for water quality? "],["conclusion.html", "Chapter 8 Conclusion", " Chapter 8 Conclusion This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
